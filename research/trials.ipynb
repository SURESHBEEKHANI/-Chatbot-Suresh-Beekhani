{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Chatbot-Suresh-Beekhani\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Chatbot-Suresh-Beekhani'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # For splitting text into chunks\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # HuggingFace embedding model for converting text to vectors\n",
    "from langchain_qdrant import QdrantVectorStore  # type: ignore # For storing vectors in Qdrant # To load documents from the web (correct import statement)\n",
    "import os  # Standard library for interacting with the operating system\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qdrant_api_key=os.environ.get('qdrant_api_key') \n",
    "groq_API_KEY=os.environ.get('groq_API_KEY')\n",
    "qdrant_url = \"https://e92b3638-9cd8-43e3-9c5d-a049f560fab2.us-east4-0.gcp.cloud.qdrant.io\"\n",
    "collection_name = \"skchatbot\"\n",
    "os.environ[\"groq_API_KEY\"] = groq_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_split_pdfs(folder_path, chunk_size, chunk_overlap):\n",
    "    \"\"\"Load PDFs from folder and split into chunks with custom separators.\"\"\"\n",
    "    \n",
    "    # Load PDF files from the folder\n",
    "    loader = DirectoryLoader(folder_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Define custom separators for splitting text\n",
    "    separators = [\n",
    "        \"\\n\\n\",  # Paragraph break\n",
    "        \"\\n\",    # Line break\n",
    "        \" \",     # Space\n",
    "        \".\",     # Full stop\n",
    "        \",\",     # Comma\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\"        # Empty separator\n",
    "    ]\n",
    "\n",
    "    # Create a text splitter with the given chunk size, overlap, and separators\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=separators\n",
    "    )\n",
    "    \n",
    "    # Split the documents into smaller chunks\n",
    "    return text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Data\"  # Path to the folder containing PDF files\n",
    "\n",
    "# Call the function with the folder path\n",
    "doc_chunks = load_and_split_pdfs(folder_path, chunk_size=500, chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0}, page_content='Suresh Beekhani - A Passionate and Skilled Machine Learning Engineer\\nSuresh Beekhani is a highly motivated and experienced Machine Learning \\nEngineer with over two years of experience in developing and deploying end-to-\\nend machine learning solutions. He possesses a strong foundation in data \\nscience, machine learning, deep learning, and natural language processing \\n(NLP). Suresh is passionate about leveraging the power of AI to extract'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0}, page_content='meaningful insights from data and solve complex business challenges. \\nKey Skills and Expertise:\\nProfessional Experience:\\nSuresh has a proven track record of success in various roles, including:\\nProjects:\\nSuresh has completed several impressive projects that demonstrate his skills \\nand creativity, such as:\\nMachine Learning: Proﬁcient in building predictive models, performing data \\nanalysis, and developing machine learning algorithms.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0}, page_content='Deep Learning: Expertise in neural networks, deep learning architectures, \\nand transfer learning techniques. \\nNatural Language Processing (NLP): Experienced in developing NLP \\napplications, including text analysis, language modeling, and chatbot \\ndevelopment. \\nProgramming Languages: Python, SQL, HTML, CSS. \\nCloud Computing: Familiar with AWS services such as SageMaker, Lambda, \\nEC2, ECR, ECS, EKS, Amazon API Gateway, and S3. \\nTools and Technologies: Anaconda, VS Code, Jupyter Notebook, Google'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0}, page_content='Colab, Git, DVC, GitHub Actions, Jenkins, Docker, MLﬂow, Scikit-learn, \\nTensorFlow, Keras, Transformers, Flask, and FastAPI. \\nGenerative AI Engineer (Freelance): Successfully delivered cutting-edge AI \\nsolutions to clients globally, specializing in areas like predictive modeling, \\nNLP, and deep learning. \\nMachine Learning Engineer (Freelance): Provided high-quality, customized \\nmachine learning solutions to diverse clients on Upwork.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0}, page_content='Associate Machine Learning Engineer (Avanza Solutions): Developed and \\ndeployed machine learning models for tasks such as student exam \\nperformance prediction and loan eligibility prediction.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 1}, page_content=\"Education and Continuous Learning:\\nSuresh holds a Bachelor's degree in Computer Science and continuously \\nupdates his skills through online courses and certiﬁcations in areas like Python, \\nSQL, and Data Science. \\nA Collaborative and Results-Oriented Individual:\\nSuresh is a highly collaborative and results-oriented individual with excellent \\ncommunication and problem-solving skills. He is eager to contribute his \\nexpertise and passion to challenging projects and make a signiﬁcant impact in\"),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 1}, page_content='the ﬁeld of AI. 1 \\n1. Suresh_ml_Resume.pdf\\nI specialize in providing cutting-edge machine learning solutions, with a strong \\nfocus on Generative AI (GenAI), to address a wide range of business challenges. \\nMy services encompass:\\nStudent Exam Performance Prediction: Developed a machine learning \\nmodel to accurately predict student scores based on various factors. \\nLoan Eligibility Prediction: Built a user-friendly web application for real-\\ntime loan approval prediction.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 1}, page_content='Movie Recommender System: Created a content-based movie \\nrecommendation system. \\nWhatsApp Conversations Analysis: Developed a Streamlit app for insightful \\nanalysis of WhatsApp chat history. \\nChat-with-Postgres-SQL: Built a Streamlit app enabling natural language \\ninteraction with PostgreSQL databases. \\nGenAI Model Development:\\nDesigning and implementing innovative GenAI models for tasks such as \\ntext generation, image creation, and music composition.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 1}, page_content='Leveraging advanced techniques like di\\x00usion models, transformers, and \\nvariational autoencoders.\\nDeveloping creative and practical applications of GenAI, including \\ncontent creation, personalized experiences, and novel product design.\\nMachine Learning Model Development:\\nBuilding custom machine learning models for tasks such as prediction, \\nclassiﬁcation, and clustering.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 2}, page_content='Utilizing a variety of algorithms and techniques, including supervised, \\nunsupervised, and reinforcement learning.\\nDeveloping models for various applications, including customer churn \\nprediction, fraud detection, and sales forecasting.\\nDeep Learning Solutions:\\nDesigning and implementing deep learning models for complex tasks like \\nimage recognition, natural language processing, and time series analysis.\\nLeveraging deep learning frameworks such as TensorFlow and Keras to'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 2}, page_content='build and train neural networks.\\nDeveloping solutions for applications such as object detection, machine \\ntranslation, and sentiment analysis.\\nNatural Language Processing (NLP) Expertise:\\nCreating NLP applications for text analysis, language understanding, and \\nconversational AI.\\nDeveloping solutions for tasks like text summarization, sentiment \\nanalysis, and chatbot development.\\nUtilizing NLP libraries and techniques to process and analyze textual data.\\nData Analysis and Visualization:'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 2}, page_content='Performing exploratory data analysis to uncover patterns and insights \\nfrom data.\\nCreating compelling visualizations to communicate ﬁndings e\\x00ectively.\\nUtilizing data analysis tools and techniques to extract meaningful \\ninformation from data.\\nCloud-Based Machine Learning:\\nDeploying and managing machine learning models on cloud platforms like \\nAWS.\\nUtilizing cloud services such as SageMaker, Lambda, and EC2 for scalable \\nand e\\x00cient model deployment.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 2}, page_content='Building and deploying serverless machine learning applications.\\nAgent Development:\\nDesigning and building intelligent agents capable of autonomous action \\nand decision-making.\\nIntegrating agents with machine learning models and external data \\nsources.\\nDeveloping agent-based systems for applications such as customer \\nservice, robotics, and game AI.\\nRAG Server Implementation:\\nDesigning and implementing Retrieval-Augmented Generation (RAG) \\nservers for enhanced LLM performance.'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 3}, page_content='In addition to the above, I also o\\x00er:\\nIntegrating external knowledge bases and data sources with LLMs to \\nimprove accuracy and relevance.\\nBuilding scalable and e\\x00cient RAG systems for real-world applications.\\nMachine Learning Consulting: Providing expert advice on machine learning \\nstrategy and implementation, with a focus on integrating GenAI solutions, \\nagents, and RAG systems.\\nData Science Training: Conducting workshops and training sessions on'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 3}, page_content='machine learning and data science topics, including specialized training on \\nGenAI, agents, and RAG.\\nFreelance Machine Learning Projects: Undertaking freelance projects to \\ndeliver customized machine learning solutions, incorporating GenAI, agents, \\nand RAG where appropriate.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURESH BEEKHANI\\AppData\\Local\\Temp\\ipykernel_12676\\1255207922.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
      "c:\\conda_envs\\mychatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QdrantVectorStore with documents and embedding model\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    documents=doc_chunks,              # List of Document objects to be stored in the vector store\n",
    "    embedding=embeddings,              # Embedding model used to convert documents into vectors\n",
    "    url=qdrant_url,                    # URL for the Qdrant service\n",
    "    api_key=qdrant_api_key,            # API key for accessing the Qdrant service\n",
    "    collection_name=collection_name    # Name of the collection to store the vectors in\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name= collection_name,\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"Suresh beekhani ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0, '_id': '1846b96e-c7f0-4b1d-9397-5e9b3c5a85ec', '_collection_name': 'skchatbot'}, page_content='Suresh Beekhani - A Passionate and Skilled Machine Learning Engineer\\nSuresh Beekhani is a highly motivated and experienced Machine Learning \\nEngineer with over two years of experience in developing and deploying end-to-\\nend machine learning solutions. He possesses a strong foundation in data \\nscience, machine learning, deep learning, and natural language processing \\n(NLP). Suresh is passionate about leveraging the power of AI to extract'),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 1, '_id': 'dd064ec6-8801-4bfd-ae51-48b66240a6cc', '_collection_name': 'skchatbot'}, page_content=\"Education and Continuous Learning:\\nSuresh holds a Bachelor's degree in Computer Science and continuously \\nupdates his skills through online courses and certiﬁcations in areas like Python, \\nSQL, and Data Science. \\nA Collaborative and Results-Oriented Individual:\\nSuresh is a highly collaborative and results-oriented individual with excellent \\ncommunication and problem-solving skills. He is eager to contribute his \\nexpertise and passion to challenging projects and make a signiﬁcant impact in\"),\n",
       " Document(metadata={'source': 'Data\\\\Suresh Beekhani.pdf', 'page': 0, '_id': 'e7ebea5a-ccf2-4598-8bcd-bbe4859e5d3f', '_collection_name': 'skchatbot'}, page_content='meaningful insights from data and solve complex business challenges. \\nKey Skills and Expertise:\\nProfessional Experience:\\nSuresh has a proven track record of success in various roles, including:\\nProjects:\\nSuresh has completed several impressive projects that demonstrate his skills \\nand creativity, such as:\\nMachine Learning: Proﬁcient in building predictive models, performing data \\nanalysis, and developing machine learning algorithms.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(groq_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    api_key=groq_API_KEY,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define a concise and informative system instruction\n",
    "system_instruction = \"\"\"\n",
    "You are a concise and informative question-answering assistant. \n",
    "Use the provided context to answer the question accurately. \n",
    "If you don't know the answer, admit it honestly. \n",
    "Keep your response concise, ideally within three sentences.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Create a ChatPromptTemplate with the system instruction\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_instruction),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suresh Beekhani is a highly motivated and experienced Machine Learning Engineer with over two years of experience in developing and deploying end-to-end machine learning solutions. He has a strong foundation in data science, machine learning, and natural language processing. Suresh is passionate about leveraging AI to extract meaningful insights from data and solve complex business challenges.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Who is Suresh beekhan\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suresh Beekhani provides services as a Machine Learning Engineer, specifically in developing and deploying end-to-end machine learning solutions. He leverages AI to extract meaningful insights from data and solve complex business challenges. His key skills include machine learning, deep learning, and natural language processing (NLP).\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Which  service  provide suresh beekhani   ?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
